{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMrA5dMVI0GJ"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import requests"
      ],
      "metadata": {
        "id": "SS-DIi6uI2y_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'sk-proj-TD018T5QIniPQAACFMYkT3BlbkFJ2ZZETuebdVQSSLZTQDDp'"
      ],
      "metadata": {
        "id": "6CXJKnf_I_4R"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://umdbands.com/mighty\"\n",
        "language = \"english\"\n",
        "word_count = 200"
      ],
      "metadata": {
        "id": "zwLBC0PDMCx8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an intelligent assistant, skilled in summarizing data and information from websites, given a url.\"},\n",
        "  ]"
      ],
      "metadata": {
        "id": "xtDh_7HFR6jH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_website(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            return response.text\n",
        "        else:\n",
        "            print(\"Failed to fetch website. Status code:\", response.status_code)\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching website:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "Td_lpl_PUzlA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key = 'sk-proj-TD018T5QIniPQAACFMYkT3BlbkFJ2ZZETuebdVQSSLZTQDDp')\n",
        "'''\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an intelligent assistant, skilled in summarizing data and information from websites.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Summarize the information on the website https://umdbands.com/mighty .\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)\n",
        "'''\n",
        "run = True\n",
        "while run:\n",
        "  message = input(\"User: \")\n",
        "  if \"terminate\" in message:\n",
        "    break\n",
        "  if message:\n",
        "    messages.append(\n",
        "        {\"role\": \"user\", \"content\": message },\n",
        "    )\n",
        "    chat = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages = messages\n",
        "    )\n",
        "\n",
        "  reply = chat.choices[0].message.content\n",
        "  print(f\"Assistant:  {reply}\")\n",
        "  messages.append({\"role\": \"assistant\", \"content\" : reply})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpyHlUEtO2pV",
        "outputId": "c714d02a-9c36-48ee-93e9-b3b78a3acc1f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: summarize https://umdbands.com/mighty\n",
            "Assistant:  The University of Minnesota Marching Band, also known as \"The Pride of Minnesota,\" is one of the oldest and most recognized university marching bands in the United States. They perform at various events including football games, parades, and concerts. The band is made up of over 320 members who showcase precision drills, high-energy music, and intricate marching formations. They have a rich history of traditions and milestones, and their performances are known for their high level of entertainment and showmanship.\n",
            "User: summarize https://tbdbitl.osu.edu/\n",
            "Assistant:  The Ohio State University Marching Band, also known as \"The Best Damn Band in the Land\" (TBDBITL), is a renowned college marching band famous for its elaborate halftime performances at football games. With a long history dating back to the late 19th century, the band is known for its impressive formations, intricate patterns, and high-energy performances that entertain crowds of all sizes. TBDBITL showcases a diverse repertoire of music genres and engages in various traditions that have become iconic at Ohio State University. The band comprises approximately 225 members who exemplify precision, dedication, and musical excellence in their performances.\n",
            "User: terminate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio pypdf tiktoken langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yI2e20kRhhl",
        "outputId": "2a52baea-1c3b-49df-b88d-62c927809adb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.6/314.6 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-TD018T5QIniPQAACFMYkT3BlbkFJ2ZZETuebdVQSSLZTQDDp\""
      ],
      "metadata": {
        "id": "7whtIZ10Z_Ju"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q PyPDF2"
      ],
      "metadata": {
        "id": "YggfBex2bo-b"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "_AXDzQORXQUr"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(path):\n",
        "  reader = PyPDF2.PdfReader(path)\n",
        "  text = \"\"\n",
        "  num_pages = len(reader.pages)\n",
        "  for page_number in range(num_pages):\n",
        "    page = reader.pages[page_number]\n",
        "    text += page.extract_text()\n",
        "  messages.append(\n",
        "        {\"role\": \"user\", \"content\": text },\n",
        "    )\n",
        "  chat = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages = messages\n",
        "    )\n",
        "  return chat.choices[0].message.content\n",
        "  '''\n",
        "  loader = PyPDFLoader(path)\n",
        "  docs = loader.load_and_split()\n",
        "  chain = load_summarize_chain(OpenAI(temperature=0), chain_type=\"map_reduce\")\n",
        "  summary = chain.run(docs)\n",
        "  return summary\n",
        "  '''"
      ],
      "metadata": {
        "id": "1B1JIDUkXeWl"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = summarize(input())\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJaucxXmX37P",
        "outputId": "be6eafb1-3c97-4c32-90ee-299ccba9f492"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MMM_Set_List_2.pdf\n",
            "Here is a summarized list of the setlist in order for the performance:\n",
            "\n",
            "1. Hail Sinfonia - Charles E. Lutton / Arthur Sullivan\n",
            "2. Sinfonia Hymn - Charles Bennet / William Gardner\n",
            "3. Red and Black Epsilon Chapter\n",
            "4. For the Longest Time - Billy Joel\n",
            "5. Sing of Sinfonia - David Plank / C.V. Plank\n",
            "6. Brother at the Door - Herbert J. Jenny / Ben Harris\n",
            "7. Serenade to a Girl\n",
            "8. Brown Eyes\n",
            "9. Ode\n",
            "10. Good Night - Matthew Killian\n",
            "11. Vive L’Amour - Stephen Fay\n",
            "12. Brother to Brother\n",
            "13. Parting Song - Rudolph R. Willman / Ralph Howard Pendleton\n",
            "\n",
            "The setlist seems to consist of a mix of classical, contemporary, and original music pieces tailored for the performance.\n"
          ]
        }
      ]
    }
  ]
}